{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(csv_file, sequence_length):\n",
    "    \n",
    "  \n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    features = df[['magnitude', 'cdi', 'mmi', 'dmin', 'gap', 'depth']].values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    normalized_features = scaler.fit_transform(features)\n",
    "    \n",
    "    sequences = []\n",
    "    for i in range(0, len(normalized_features) - sequence_length + 1, sequence_length // 2):  \n",
    "        sequence = normalized_features[i:i + sequence_length]\n",
    "        sequences.append(sequence)\n",
    "    \n",
    "    return torch.FloatTensor(sequences), scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6002/2731436145.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400268359/work/torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  return torch.FloatTensor(sequences), scaler\n"
     ]
    }
   ],
   "source": [
    "normal_sequences, normal_scaler = preprocess_data(\"Normal.csv\", 50)\n",
    "anomalous_sequences, anomalous_scaler = preprocess_data(\"Anomalous.csv\", 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from backup import TsunamiDetector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: G_loss: 0.8808, D_loss: 0.6847\n",
      "Epoch 1: G_loss: 0.7845, D_loss: 0.7098\n",
      "Epoch 2: G_loss: 0.6776, D_loss: 0.7235\n",
      "Epoch 3: G_loss: 0.6490, D_loss: 0.7632\n",
      "Epoch 4: G_loss: 0.5771, D_loss: 0.7963\n",
      "Epoch 5: G_loss: 0.5646, D_loss: 0.7927\n",
      "Epoch 6: G_loss: 0.5760, D_loss: 0.7795\n",
      "Epoch 7: G_loss: 0.5969, D_loss: 0.7720\n",
      "Epoch 8: G_loss: 0.5908, D_loss: 0.7704\n",
      "Epoch 9: G_loss: 0.5904, D_loss: 0.7327\n",
      "Epoch 10: G_loss: 0.6050, D_loss: 0.7268\n",
      "Epoch 11: G_loss: 0.6575, D_loss: 0.7142\n",
      "Epoch 12: G_loss: 0.6799, D_loss: 0.6765\n",
      "Epoch 13: G_loss: 0.6984, D_loss: 0.7019\n",
      "Epoch 14: G_loss: 0.6762, D_loss: 0.7209\n",
      "Epoch 15: G_loss: 0.6863, D_loss: 0.7089\n",
      "Epoch 16: G_loss: 0.7015, D_loss: 0.6934\n",
      "Epoch 17: G_loss: 0.6972, D_loss: 0.7000\n",
      "Epoch 18: G_loss: 0.7353, D_loss: 0.6398\n",
      "Epoch 19: G_loss: 0.7047, D_loss: 0.6697\n",
      "Epoch 20: G_loss: 0.7783, D_loss: 0.6549\n",
      "Epoch 21: G_loss: 0.7804, D_loss: 0.6667\n",
      "Epoch 22: G_loss: 0.7917, D_loss: 0.6290\n",
      "Epoch 23: G_loss: 0.7948, D_loss: 0.6317\n",
      "Epoch 24: G_loss: 0.7764, D_loss: 0.6340\n",
      "Epoch 25: G_loss: 0.7969, D_loss: 0.6111\n",
      "Epoch 26: G_loss: 0.8503, D_loss: 0.6230\n",
      "Epoch 27: G_loss: 0.8572, D_loss: 0.5971\n",
      "Epoch 28: G_loss: 0.9490, D_loss: 0.5685\n",
      "Epoch 29: G_loss: 0.9635, D_loss: 0.5722\n",
      "Epoch 30: G_loss: 0.9242, D_loss: 0.5726\n",
      "Epoch 31: G_loss: 0.9897, D_loss: 0.6027\n",
      "Epoch 32: G_loss: 0.8662, D_loss: 0.6087\n",
      "Epoch 33: G_loss: 0.8545, D_loss: 0.5847\n",
      "Epoch 34: G_loss: 0.9357, D_loss: 0.5715\n",
      "Epoch 35: G_loss: 0.9509, D_loss: 0.5691\n",
      "Epoch 36: G_loss: 0.9309, D_loss: 0.5766\n",
      "Epoch 37: G_loss: 0.9587, D_loss: 0.5579\n",
      "Epoch 38: G_loss: 1.0280, D_loss: 0.5799\n",
      "Epoch 39: G_loss: 1.0011, D_loss: 0.5183\n",
      "Epoch 40: G_loss: 0.9824, D_loss: 0.5537\n",
      "Epoch 41: G_loss: 0.9422, D_loss: 0.5330\n",
      "Epoch 42: G_loss: 0.8335, D_loss: 0.5364\n",
      "Epoch 43: G_loss: 0.7957, D_loss: 0.5753\n",
      "Epoch 44: G_loss: 0.8049, D_loss: 0.5651\n",
      "Epoch 45: G_loss: 0.8920, D_loss: 0.5335\n",
      "Epoch 46: G_loss: 0.9605, D_loss: 0.4807\n",
      "Epoch 47: G_loss: 1.0211, D_loss: 0.4869\n",
      "Epoch 48: G_loss: 1.0281, D_loss: 0.4802\n",
      "Epoch 49: G_loss: 1.0141, D_loss: 0.5230\n",
      "Epoch 50: G_loss: 1.0495, D_loss: 0.5065\n",
      "Epoch 51: G_loss: 1.0106, D_loss: 0.4933\n",
      "Epoch 52: G_loss: 0.9097, D_loss: 0.5362\n",
      "Epoch 53: G_loss: 0.8973, D_loss: 0.5086\n",
      "Epoch 54: G_loss: 0.9277, D_loss: 0.5212\n",
      "Epoch 55: G_loss: 0.8926, D_loss: 0.5007\n",
      "Epoch 56: G_loss: 1.0118, D_loss: 0.4934\n",
      "Epoch 57: G_loss: 0.9879, D_loss: 0.4965\n",
      "Epoch 58: G_loss: 1.0653, D_loss: 0.5020\n",
      "Epoch 59: G_loss: 1.1803, D_loss: 0.4603\n",
      "Epoch 60: G_loss: 1.1628, D_loss: 0.4633\n",
      "Epoch 61: G_loss: 1.2277, D_loss: 0.4304\n",
      "Epoch 62: G_loss: 1.0958, D_loss: 0.4937\n",
      "Epoch 63: G_loss: 1.1378, D_loss: 0.4398\n",
      "Epoch 64: G_loss: 1.2421, D_loss: 0.4117\n",
      "Epoch 65: G_loss: 1.0831, D_loss: 0.4419\n",
      "Epoch 66: G_loss: 1.1914, D_loss: 0.4114\n",
      "Epoch 67: G_loss: 1.1218, D_loss: 0.4301\n",
      "Epoch 68: G_loss: 1.2597, D_loss: 0.4229\n",
      "Epoch 69: G_loss: 1.1718, D_loss: 0.4337\n",
      "Epoch 70: G_loss: 1.1637, D_loss: 0.4607\n",
      "Epoch 71: G_loss: 1.0667, D_loss: 0.4276\n",
      "Epoch 72: G_loss: 1.0303, D_loss: 0.4241\n",
      "Epoch 73: G_loss: 1.0766, D_loss: 0.4707\n",
      "Epoch 74: G_loss: 1.0583, D_loss: 0.4465\n",
      "Epoch 75: G_loss: 1.1735, D_loss: 0.4361\n",
      "Epoch 76: G_loss: 1.1383, D_loss: 0.4545\n",
      "Epoch 77: G_loss: 1.0678, D_loss: 0.4495\n",
      "Epoch 78: G_loss: 1.0619, D_loss: 0.4008\n",
      "Epoch 79: G_loss: 1.2608, D_loss: 0.4147\n",
      "Epoch 80: G_loss: 1.3789, D_loss: 0.4252\n",
      "Epoch 81: G_loss: 1.3498, D_loss: 0.4335\n",
      "Epoch 82: G_loss: 1.3415, D_loss: 0.3841\n",
      "Epoch 83: G_loss: 1.4753, D_loss: 0.3347\n",
      "Epoch 84: G_loss: 1.3471, D_loss: 0.3279\n",
      "Epoch 85: G_loss: 1.2798, D_loss: 0.3393\n",
      "Epoch 86: G_loss: 1.3313, D_loss: 0.3146\n",
      "Epoch 87: G_loss: 1.3186, D_loss: 0.3713\n",
      "Epoch 88: G_loss: 1.3061, D_loss: 0.3373\n",
      "Epoch 89: G_loss: 1.3172, D_loss: 0.3262\n",
      "Epoch 90: G_loss: 1.3271, D_loss: 0.3440\n",
      "Epoch 91: G_loss: 1.5321, D_loss: 0.3273\n",
      "Epoch 92: G_loss: 1.3620, D_loss: 0.3206\n",
      "Epoch 93: G_loss: 1.3852, D_loss: 0.3083\n",
      "Epoch 94: G_loss: 1.3138, D_loss: 0.3197\n",
      "Epoch 95: G_loss: 1.3077, D_loss: 0.3660\n",
      "Epoch 96: G_loss: 1.2816, D_loss: 0.3253\n",
      "Epoch 97: G_loss: 1.4102, D_loss: 0.3221\n",
      "Epoch 98: G_loss: 1.3860, D_loss: 0.3224\n",
      "Epoch 99: G_loss: 1.5135, D_loss: 0.2990\n",
      "Epoch 100: G_loss: 1.4878, D_loss: 0.2870\n",
      "Epoch 101: G_loss: 1.5543, D_loss: 0.3042\n",
      "Epoch 102: G_loss: 1.4816, D_loss: 0.2834\n",
      "Epoch 103: G_loss: 1.4504, D_loss: 0.2688\n",
      "Epoch 104: G_loss: 1.5195, D_loss: 0.2710\n",
      "Epoch 105: G_loss: 1.4029, D_loss: 0.3175\n",
      "Epoch 106: G_loss: 1.4590, D_loss: 0.3015\n",
      "Epoch 107: G_loss: 1.6044, D_loss: 0.2896\n",
      "Epoch 108: G_loss: 1.4579, D_loss: 0.2689\n",
      "Epoch 109: G_loss: 1.6582, D_loss: 0.2568\n",
      "Epoch 110: G_loss: 1.6575, D_loss: 0.2474\n",
      "Epoch 111: G_loss: 1.6191, D_loss: 0.2711\n",
      "Epoch 112: G_loss: 1.8388, D_loss: 0.2388\n",
      "Epoch 113: G_loss: 1.7370, D_loss: 0.2164\n",
      "Epoch 114: G_loss: 1.8718, D_loss: 0.2096\n",
      "Epoch 115: G_loss: 1.7862, D_loss: 0.2256\n",
      "Epoch 116: G_loss: 1.8008, D_loss: 0.2366\n",
      "Epoch 117: G_loss: 1.6848, D_loss: 0.2320\n",
      "Epoch 118: G_loss: 1.6659, D_loss: 0.2139\n",
      "Epoch 119: G_loss: 1.4154, D_loss: 0.2698\n",
      "Epoch 120: G_loss: 1.4516, D_loss: 0.2449\n",
      "Epoch 121: G_loss: 1.4970, D_loss: 0.2335\n",
      "Epoch 122: G_loss: 1.6491, D_loss: 0.2269\n",
      "Epoch 123: G_loss: 1.7371, D_loss: 0.2370\n",
      "Epoch 124: G_loss: 1.6921, D_loss: 0.2164\n",
      "Epoch 125: G_loss: 1.8199, D_loss: 0.2142\n",
      "Epoch 126: G_loss: 1.8745, D_loss: 0.2355\n",
      "Epoch 127: G_loss: 1.8926, D_loss: 0.1921\n",
      "Epoch 128: G_loss: 1.9721, D_loss: 0.1927\n",
      "Epoch 129: G_loss: 1.7706, D_loss: 0.1931\n",
      "Epoch 130: G_loss: 1.8343, D_loss: 0.1947\n",
      "Epoch 131: G_loss: 1.5601, D_loss: 0.2552\n",
      "Epoch 132: G_loss: 1.3740, D_loss: 0.2926\n",
      "Epoch 133: G_loss: 1.5598, D_loss: 0.2929\n",
      "Epoch 134: G_loss: 1.6999, D_loss: 0.2186\n",
      "Epoch 135: G_loss: 1.8020, D_loss: 0.2119\n",
      "Epoch 136: G_loss: 1.8758, D_loss: 0.2175\n",
      "Epoch 137: G_loss: 1.9350, D_loss: 0.2179\n",
      "Epoch 138: G_loss: 1.9489, D_loss: 0.1977\n",
      "Epoch 139: G_loss: 1.9171, D_loss: 0.2091\n",
      "Epoch 140: G_loss: 1.9015, D_loss: 0.1824\n",
      "Epoch 141: G_loss: 1.9726, D_loss: 0.1830\n",
      "Epoch 142: G_loss: 1.9462, D_loss: 0.2007\n",
      "Epoch 143: G_loss: 2.0455, D_loss: 0.1706\n",
      "Epoch 144: G_loss: 2.0255, D_loss: 0.1658\n",
      "Epoch 145: G_loss: 2.0268, D_loss: 0.1583\n",
      "Epoch 146: G_loss: 2.0087, D_loss: 0.1532\n",
      "Epoch 147: G_loss: 2.0397, D_loss: 0.1549\n",
      "Epoch 148: G_loss: 2.0783, D_loss: 0.1484\n",
      "Epoch 149: G_loss: 1.9862, D_loss: 0.1629\n",
      "Epoch 150: G_loss: 1.9803, D_loss: 0.1669\n",
      "Epoch 151: G_loss: 1.9884, D_loss: 0.1614\n",
      "Epoch 152: G_loss: 2.0299, D_loss: 0.1737\n",
      "Epoch 153: G_loss: 2.1328, D_loss: 0.1655\n",
      "Epoch 154: G_loss: 2.1198, D_loss: 0.1566\n",
      "Epoch 155: G_loss: 2.2344, D_loss: 0.1515\n",
      "Epoch 156: G_loss: 2.1864, D_loss: 0.1468\n",
      "Epoch 157: G_loss: 2.2814, D_loss: 0.1288\n",
      "Epoch 158: G_loss: 2.2181, D_loss: 0.1507\n",
      "Epoch 159: G_loss: 2.0789, D_loss: 0.1714\n",
      "Epoch 160: G_loss: 1.8463, D_loss: 0.1868\n",
      "Epoch 161: G_loss: 1.9572, D_loss: 0.1798\n",
      "Epoch 162: G_loss: 2.0276, D_loss: 0.1631\n",
      "Epoch 163: G_loss: 2.1558, D_loss: 0.1712\n",
      "Epoch 164: G_loss: 2.0859, D_loss: 0.1468\n",
      "Epoch 165: G_loss: 2.0854, D_loss: 0.1845\n",
      "Epoch 166: G_loss: 1.9906, D_loss: 0.1724\n",
      "Epoch 167: G_loss: 2.2456, D_loss: 0.1544\n",
      "Epoch 168: G_loss: 2.1545, D_loss: 0.1575\n",
      "Epoch 169: G_loss: 2.2394, D_loss: 0.1556\n",
      "Epoch 170: G_loss: 2.2052, D_loss: 0.1426\n",
      "Epoch 171: G_loss: 2.2356, D_loss: 0.1335\n",
      "Epoch 172: G_loss: 2.3109, D_loss: 0.1475\n",
      "Epoch 173: G_loss: 2.1803, D_loss: 0.1223\n",
      "Epoch 174: G_loss: 2.2651, D_loss: 0.1224\n",
      "Epoch 175: G_loss: 2.1691, D_loss: 0.1381\n",
      "Epoch 176: G_loss: 2.2131, D_loss: 0.1094\n",
      "Epoch 177: G_loss: 2.4010, D_loss: 0.1148\n",
      "Epoch 178: G_loss: 2.1039, D_loss: 0.1508\n",
      "Epoch 179: G_loss: 2.2424, D_loss: 0.1361\n",
      "Epoch 180: G_loss: 2.3392, D_loss: 0.1334\n",
      "Epoch 181: G_loss: 2.0851, D_loss: 0.1241\n",
      "Epoch 182: G_loss: 1.9017, D_loss: 0.1889\n",
      "Epoch 183: G_loss: 1.9357, D_loss: 0.2153\n",
      "Epoch 184: G_loss: 2.1137, D_loss: 0.1600\n",
      "Epoch 185: G_loss: 2.2683, D_loss: 0.1538\n",
      "Epoch 186: G_loss: 2.0684, D_loss: 0.1653\n",
      "Epoch 187: G_loss: 2.0400, D_loss: 0.1614\n",
      "Epoch 188: G_loss: 1.9037, D_loss: 0.1802\n",
      "Epoch 189: G_loss: 1.9823, D_loss: 0.1738\n",
      "Epoch 190: G_loss: 2.1243, D_loss: 0.1877\n",
      "Epoch 191: G_loss: 1.9324, D_loss: 0.1731\n",
      "Epoch 192: G_loss: 2.0973, D_loss: 0.1629\n",
      "Epoch 193: G_loss: 2.1501, D_loss: 0.1713\n",
      "Epoch 194: G_loss: 2.1417, D_loss: 0.1674\n",
      "Epoch 195: G_loss: 2.0575, D_loss: 0.1972\n",
      "Epoch 196: G_loss: 2.2228, D_loss: 0.1906\n",
      "Epoch 197: G_loss: 2.3629, D_loss: 0.1307\n",
      "Epoch 198: G_loss: 2.1814, D_loss: 0.1613\n",
      "Epoch 199: G_loss: 2.0619, D_loss: 0.1729\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "sequence_length = 50  # Sequence length for training (you already have it)\n",
    "latent_dim = 100  # Latent dimension for the generator (can be adjusted)\n",
    "lambda_ano = 0.1 # Weight for anomaly loss\n",
    "num_features = 6 # Number of features (as in the input data)\n",
    "\n",
    "\n",
    "# Create the TsunamiDetector instance\n",
    "tsunami_detector = TsunamiDetector(sequence_length, latent_dim, lambda_ano, num_features,device='cpu')\n",
    "\n",
    "# Train the model on the normal sequences (normal_sequences is already preprocessed)\n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "\n",
    "# Convert normal_sequences to a DataLoader compatible format (TensorDataset)\n",
    "normal_data = TensorDataset(normal_sequences)\n",
    "normal_dataloader = DataLoader(normal_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "tsunami_detector.train(normal_dataloader, epochs=epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated threshold: 3.057793378829956\n"
     ]
    }
   ],
   "source": [
    "# Calibrate threshold with normal data\n",
    "validation_data = normal_sequences  # You can use a validation set or a portion of normal data\n",
    "threshold_percentile = 95\n",
    "threshold = tsunami_detector.calibrate_threshold(validation_data, percentile=threshold_percentile)\n",
    "\n",
    "print(f\"Calibrated threshold: {threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOMALY: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.86704421043396\n",
      "ANOMALY: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 2.2189674377441406\n",
      "ANOMALY: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.8718364238739014\n",
      "ANOMALY: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.5545028448104858\n",
      "ANOMALY: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.8520749807357788\n",
      "ANOMALY: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.9115089178085327\n",
      "ANOMALY: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.775671362876892\n",
      "ANOMALY: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.5681381225585938\n",
      "ANOMALY: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.7589538097381592\n",
      "ANOMALY: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.6434121131896973\n",
      "ANOMALY: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.8370535373687744\n",
      "ANOMALY: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 2.14249324798584\n"
     ]
    }
   ],
   "source": [
    "# Assuming anomalous_sequences is a tensor of anomalous data (like actual tsunami events)\n",
    "anomalous_sequences = torch.FloatTensor(anomalous_sequences)  # Ensure it's a tensor if not already\n",
    "\n",
    "# Evaluate anomalous data\n",
    "for sequence in anomalous_sequences:\n",
    "    result = tsunami_detector.detect_tsunami(sequence)\n",
    "    print(f\"ANOMALY: Is Tsunami: {result['is_tsunami']}, Confidence: {result['confidence']}, Anomaly Score: {result['anomaly_score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL: Is Tsunami: True, Confidence: 1.0, Anomaly Score: 3.336440086364746\n",
      "NORMAL: Is Tsunami: True, Confidence: 1.0, Anomaly Score: 3.471646785736084\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 2.2186741828918457\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 2.2597107887268066\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 2.2022886276245117\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.3016515970230103\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.3189741373062134\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.5805974006652832\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.915256142616272\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.654782772064209\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.0934669971466064\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.2396166324615479\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.748955249786377\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.4862759113311768\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.4734513759613037\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.6672435998916626\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.7621774673461914\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.6442270278930664\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.69315767288208\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.7325830459594727\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.870965838432312\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.714532732963562\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.5905157327651978\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.6441757678985596\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.8004180192947388\n",
      "NORMAL: Is Tsunami: False, Confidence: 1.0, Anomaly Score: 1.9661595821380615\n"
     ]
    }
   ],
   "source": [
    "normal_sequences = torch.FloatTensor(normal_sequences)  # Ensure it's a tensor if not already\n",
    "\n",
    "# Evaluate anomalous data\n",
    "for sequence in normal_sequences:\n",
    "    result = tsunami_detector.detect_tsunami(sequence)\n",
    "    print(f\"NORMAL: Is Tsunami: {result['is_tsunami']}, Confidence: {result['confidence']}, Anomaly Score: {result['anomaly_score']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
